# -*- coding: utf-8 -*-
"""LUNG_CANCER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16DedBORJpnZbXoaM95ibVnF61YoqKELy
"""

import pandas as pd ## importing libraries for dataset
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.decomposition import PCA

df = pd.read_csv('/content/Lung_Cancer_dataset.csv')  ##loading the dataset

df.shape ##check the size of dataset

df.head() ## first 5 lines of dataset

df.info() ##include all the imp info

df.isnull().sum() ## checking missing values and suming up

label_encoder = LabelEncoder() ### Encode categorical variables
categorical_cols = df.select_dtypes(include=['object']).columns

for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

X = df.drop('Result', axis=1) ## Separate features and target
y = df['Result']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Data are splited into 80% Train- 20% test data

scaler = StandardScaler() ## Scale features
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("\n=== DECISION TREE ===") ##Decision Tree
dt_baseline = DecisionTreeClassifier(random_state=42, max_depth=5)
dt_baseline.fit(X_train_scaled, y_train)
y_pred_baseline = dt_baseline.predict(X_test_scaled)

accuracy_baseline = accuracy_score(y_test, y_pred_baseline) ##evaluate the tree
precision_baseline = precision_score(y_test, y_pred_baseline)
recall_baseline = recall_score(y_test, y_pred_baseline)
f1_baseline = f1_score(y_test, y_pred_baseline)

print(accuracy_baseline) ## printing the results
print(precision_baseline)
print(recall_baseline)
print(f1_baseline)

cm_baseline = confusion_matrix(y_test, y_pred_baseline) ##confusion matrix
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues')
plt.title('Baseline DT Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')

##  feature importance
 feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': dt_baseline.feature_importances_
}).sort_values('importance', ascending=False)


print(feature_importance.head(5))

pca = PCA() # PCA Analysis
X_train_pca = pca.fit_transform(X_train_scaled)
cumulative_variance = np.cumsum(pca.explained_variance_ratio_)
n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1

print({n_components_95})

pca_optimal = PCA(n_components=n_components_95) # Apply PCA
X_train_pca_optimal = pca_optimal.fit_transform(X_train_scaled)
X_test_pca_optimal = pca_optimal.transform(X_test_scaled)

print("\n=== DECISION TREE WITH PCA ===") # Decision Tree with PCA
dt_pca = DecisionTreeClassifier(random_state=42, max_depth=5)
dt_pca.fit(X_train_pca_optimal, y_train)
y_pred_pca = dt_pca.predict(X_test_pca_optimal)

accuracy_pca = accuracy_score(y_test, y_pred_pca) # Evaluate PCA model
precision_pca = precision_score(y_test, y_pred_pca)
recall_pca = recall_score(y_test, y_pred_pca)
f1_pca = f1_score(y_test, y_pred_pca)

print(accuracy_pca) ##printing the result
print(precision_pca)
print(recall_pca)
print(f1_pca)

cm_pca = confusion_matrix(y_test, y_pred_pca) # Confusion matrix for PCA
plt.subplot(1, 2, 2)
sns.heatmap(cm_pca, annot=True, fmt='d', cmap='Reds')
plt.title('PCA DT Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.tight_layout()
plt.show()

print("\n=== RESULTS COMPARISON ===") # Results comparison
comparison = pd.DataFrame({
    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],
    'Baseline': [accuracy_baseline, precision_baseline, recall_baseline, f1_baseline],
    'PCA': [accuracy_pca, precision_pca, recall_pca, f1_pca],
    'Difference': [
        accuracy_pca - accuracy_baseline,
        precision_pca - precision_baseline,
        recall_pca - recall_baseline,
        f1_pca - f1_baseline
    ]
})

print(comparison)

print("\n=== DISCUSSION ===") # Discussion
print("1. FEATURE IMPORTANCE:")
print("   The most important features for lung cancer prediction are:")
for i, row in feature_importance.head(3).iterrows():
    print(f"   - {row['feature']}: {row['importance']:.3f}")

print(f"\n2. PCA REDUCTION: {X.shape[1]} features â†’ {n_components_95} components")

print("\n3. PERFORMANCE IMPACT:")
if accuracy_pca > accuracy_baseline:
    print("   PCA improved model performance")
elif accuracy_pca < accuracy_baseline:
    print("    PCA decreased model performance")
else:
    print("   PCA had no significant effect on performance")
